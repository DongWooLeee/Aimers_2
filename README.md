# LGAimers2

# 1. 프로젝트 개요

## 1.1 배경 및 목표
- **스마트 공장** 공정데이터를 활용하여 제품의 **품질 상태(Y_Class = 0,1,2)**를 예측하고자 함.  
- 데이터는 **결측치**가 매우 많고(라인별로 센서 이벤트가 달라 결측 발생), **클래스 불균형**도 존재.  
- **해커톤**이므로, 최종적으로 **csv 파일(예측 결과)** 형태로 제출.

## 1.2 핵심 난제
1. **결측치 다량 존재**: 단순 평균/중위수로 채우기에 부담되는 스케일  
2. **라인별 센서 이벤트**가 달라, “비결측 열 집합”이 라인마다 상이  
3. **Y_Class**가 (0,1,2)로 불균형 + 0,2는 모두 ‘불량’으로 묶일 수 있는 구성 → 오분류 방지가 중요

---

# 2. 데이터 및 변수

## 2.1 제공 데이터
- **`train.csv`**  
  - 범주형: `PRODUCT_CODE`(A_31/T_31/O_31), `LINE`(6개 라인), `PRODUCT_ID`(고유 ID)  
  - 수치형: `X_1 ~ X_3326` (비식별 센서값)  
  - 타겟:
    - `Y_Quality`(연속형 지표)  
    - `Y_Class` (0/1/2)

- **`test.csv`**  
  - 동일 구조이나 `Y_Quality`, `Y_Class`가 제외됨(예측 대상)

## 2.2 라인별 특징
- 6개 라인이 서로 다른 조업조건, 센서환경 → 결측치 발생 양상 다름.  
- 특정 라인(예: 3,4)에서 뚜렷하게 **데이터 행 수가 적거나** 결측 패턴이 고르지 않은 경향 → 모델링 시 별도 전략 고려.

---

# 3. EDA (탐색적 데이터 분석)

## 3.1 범주형 변수
- **`PRODUCT_CODE`**: A_31에서 불량률이 더 높고, T_31이 상대적으로 양호.  
- **`LINE`**: 라인별 **Y_Class 분포**와 **Y_Quality 분포**가 달라, 단일 모델로 합쳤을 때 과적합/부적합 위험이 있을 수 있음.

## 3.2 결측치 분석
- 라인 내부를 보면, “동일한 결측 패턴(동일한 열이 비결측)”을 공유하는 행들이 존재 → 이를 “그룹”이라 칭함.  
- Line3,4: 그룹이 매우 세분화(각 그룹이 차지하는 행 수가 소수).  
- Line1,2,5,6: 그룹이 조금 더 통합적(한 그룹 내 행 수가 넉넉).

## 3.3 Class 불균형
- (0,1,2) 클래스 비율 편차가 존재.  
- Stratified K-Fold를 통해 검증을 진행해, 불균형으로 인한 편향을 최소화.

---

# 4. 전처리 (Preprocessing)

## 4.1 Feature Selection
- **결측 50% 초과 열 제거**  
- **값이 전부 동일(분산=0)** 열 제거  
- **완전 NaN** 열 제거  
- 상관계수 0.8 이상 열 제거도 시도했지만, 너무 많은 열이 사라져 성능 저하 → 부분 적용.

## 4.2 결측치 대체
- **그룹(“동일 결측 패턴”)** 단위로 접근을 시도: 그룹 내에서는 대부분 동일 변수들이 NaN이 아니라서, 일괄 처리가 가능.  
- 하지만 최종적으로, **0으로 대치**하는 단순 임퓨테이션 방식을 사용.  
  - 센서데이터 특성상 “이벤트가 없으면 0”인 것으로 해석 가능하다고 판단(후처리적 분석).  
  - 라인별로 정교하게 교집합/합집합을 취하는 방식(Lines 1-2, 5-6)을 테스트했으나, 결과적으로 Line 3-4를 제외하고는 큰 이점이 없었음.

---

# 5. 모델링 (Modeling)

## 5.1 핵심 아이디어
- **CatBoost Regressor**를 통해 `Y_Quality`를 예측 후, **Threshold**를 이용해 `Y_Class`(0/1/2)로 변환  
  - (추가로, **Line3·4**는 별도의 Classifier 접근을 시도하여 더 나은 성능을 확보)

## 5.2 Threshold 설정 로직
```python
a = train_df[['Y_Class','Y_Quality']].groupby('Y_Class').agg(['mean','min','max','count'])

preds = []
for p in pre_preds:
  if p <= a[('Y_Quality','max')][0]:
    preds.append(0)
  elif p <= a[('Y_Quality','min')][2]:
    preds.append(1)
  else:
    preds.append(2)
```
- 기존의 `Y_Quality`와 `Y_Class` 분포를 분석하여 최적의 threshold를 설정하였음.  

## 5.3 라인별 별도 접근

1. **Line1·2·5·6**  
   - 전체 데이터(3,4 포함)로 **CatBoost Regressor**를 학습해도 성능이 양호  
   - 1-2, 5-6 각각 그룹화·교집합/합집합 실험했지만 큰 이점이 없었음 → 단일 Regressor로 진행  

2. **Line3·4**  
   - 샘플이 적고 결측 패턴이 복잡 → Regressor로 접근 시 Threshold 변환이 잘 안 맞으며 성능 저하  
   - **별도의 CatBoost Classifier**를 라인3·4만 추출해 훈련 → Validation 시 성능 개선 확인  
   - 결국 **혼합 전략**: (1,2,5,6)→ Regressor / (3,4)→ Classifier

---

# 6. 모델 검증 및 제출

## 6.1 Stratified K-Fold
- **불균형** 대응 차원에서 **Stratified** 분할로 Repeated K-Fold Validation 진행 (5 folds)
- SMOTE·ADASYN 등 오버샘플링은 큰 효과가 없었고, Overfitting 위험만 증가 → 미사용  

## 6.2 Submission Process
- Line 1,2,5,6 의 경우 전체 라인에 대해 학습을 진행한 모델을 사용하여 Regressor로 예측  
- 기존 `submission.csv` 파일을 활용하여 최종 제출  

---

# 7. To-Do + Additional Insights
- **Incremental Learning / 주기적 모델 업데이트**  
- **Threshold 조정 가능성 검토** (불량 최소화 목적)  
- **Feature Selection 최적화** → Tree 기반 모델을 사용하여 중요 변수를 선별, 모델 경량화 가능  


